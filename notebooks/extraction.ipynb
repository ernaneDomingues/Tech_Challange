{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o codigo extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os intervalos de tempo para o DataFrame\n",
    "START_YEAR = 1970\n",
    "END_YEAR = datetime.now().year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs base para cada tipo de tabela\n",
    "URL_TEMPLATES = [\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_02\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_03&subopcao=subopt_01\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_03&subopcao=subopt_02\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_03&subopcao=subopt_03\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_03&subopcao=subopt_04\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_04\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_05&subopcao=subopt_01\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_05&subopcao=subopt_02\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_05&subopcao=subopt_03\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_05&subopcao=subopt_04\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_05&subopcao=subopt_05\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_06&subopcao=subopt_01\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_06&subopcao=subopt_02\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_06&subopcao=subopt_03\",\n",
    "    \"http://vitibrasil.cnpuv.embrapa.br/index.php?ano={year}&opcao=opt_06&subopcao=subopt_04\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica a disponibilidade da url\n",
    "def fetch_page_content(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para padronizar os nomes das colunas\n",
    "def standardize_column_name(column):\n",
    "    column = column.strip()  # Remove extra spaces\n",
    "    column = column.lower()  # Convert to lowercase\n",
    "    column = column.replace(' ', '_')  # Replace spaces with underscores\n",
    "    column = column.replace('(', '')  # Remove parentheses\n",
    "    column = column.replace(')', '')  # Remove parentheses\n",
    "    column = column.replace('.', '')  # Remove periods\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table_content_with_category(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    table = soup.find('table', class_='tb_base tb_dados')\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    headers.insert(0, 'Categoria')\n",
    "    rows = []\n",
    "\n",
    "    current_category = None\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        if len(cells) == 2:\n",
    "            product = cells[0].text.strip()\n",
    "            quantity = cells[1].text.strip().replace('.', '').replace('-', '0')\n",
    "            quantity = int(quantity) if quantity.isdigit() else 0\n",
    "\n",
    "            # Verifica se o texto está em maiúsculas e não contém números\n",
    "            if product.isupper() and not any(c.isdigit() for c in product):\n",
    "                # Se for uma linha de soma total, assume como a categoria atual\n",
    "                current_category = product\n",
    "            else:\n",
    "                # Adiciona a linha ao DataFrame com a categoria atual\n",
    "                rows.append([current_category, product, quantity])\n",
    "\n",
    "    return headers, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrai a tabela para cada ano\n",
    "def extract_table_data(url, year):\n",
    "    try:\n",
    "        content = fetch_page_content(url)\n",
    "        headers, rows = parse_table_content_with_category(content)\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        df['Ano'] = year\n",
    "        df.columns = [standardize_column_name(col) for col in df.columns]\n",
    "        df.fillna(0, inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao extrair dados do ano {year}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrai todas as tabelas dentro do intervalo de anos definido\n",
    "def extract_table_all_data(url_template, start_year, end_year):\n",
    "    all_data = pd.DataFrame()\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        url = url_template.format(year=year)\n",
    "        year_data = extract_table_data(url, year)\n",
    "        if not year_data.empty:\n",
    "            all_data = pd.concat([all_data, year_data], ignore_index=True)\n",
    "            print(f\"Dados do ano {year} extraídos com sucesso.\")\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega os headers da tabela, para ser usado como coluna no pivot_dataframe\n",
    "def get_table_headers(url, end_year):\n",
    "    content = fetch_page_content(url.format(year=end_year))\n",
    "    headers, _ = parse_table_content_with_category(content)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega o titulo da tabela e cria o nome do arquivo CSV com o datetime do dia da extração\n",
    "def get_filename_from_page(end_year, url):\n",
    "    content = fetch_page_content(url.format(year=end_year))\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    p_element = soup.find('p', {'class': 'text_center'})\n",
    "    if p_element:\n",
    "        filename_base = p_element.text.strip().replace(f' [{end_year}]', '').replace(' ', '_').replace(',', '')\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'{filename_base}_{timestamp}.csv'\n",
    "        return filename\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para salvar o DataFrame em um CSV\n",
    "def save_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequencia de execução das funções para gerar o DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = extract_table_all_data(URL_TEMPLATES[1], START_YEAR, END_YEAR)\n",
    "columns = get_table_headers(URL_TEMPLATES[1], END_YEAR)\n",
    "filename = get_filename_from_page(END_YEAR, URL_TEMPLATES[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução para salvar todos os DataFrames extraidos a partir do Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função principal para extrair dados de todos os URLs\n",
    "# def extract_and_save_all_data(url_templates, start_year, end_year):\n",
    "#     for url_template in url_templates:\n",
    "#         all_data = extract_table_all_data(url_template, start_year, end_year)\n",
    "#         if not all_data.empty:\n",
    "#             filename = get_filename_from_page(end_year, url_template)\n",
    "#             if filename:\n",
    "#                 save_to_csv(all_data, filename)\n",
    "#                 print(f\"Dados salvos em {filename}\")\n",
    "# # Executa a extração de dados\n",
    "# extract_and_save_all_data(URL_TEMPLATES, START_YEAR, END_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in URL_TEMPLATES:\n",
    "#     filename = get_filename_from_page(END_YEAR, url)\n",
    "#     print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(input_string):\n",
    "    # Remove the file extension\n",
    "    without_extension = input_string.split('.')[0]\n",
    "    \n",
    "    # Remove the date and time part\n",
    "    parts = without_extension.split('__')\n",
    "    if len(parts) > 1:\n",
    "        without_date_time = parts[0]\n",
    "    else:\n",
    "        without_date_time = parts[0].rsplit('_', 2)[0]\n",
    "    \n",
    "    # Replace special characters and adjust the format\n",
    "    result = without_date_time.lower().replace('ç', 'c').replace('ã', 'a').replace('é', 'e').replace('í', 'i').replace('ú', 'u').replace('á', 'a').replace('ó', 'o').replace('ê', 'e').replace('ô', 'o').replace(' ', '_').replace('__', '_').replace('_e_', '_').replace('_de_', '_').replace('_', '_')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = process_string(filename)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as variaveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "#Azure\n",
    "# dbname=os.getenv('PGDATABASE')\n",
    "# user=os.getenv('PGUSER')\n",
    "# password=os.getenv('PGPASSWORD')\n",
    "# host=os.getenv('PGHOST')\n",
    "# port=os.getenv('PGPORT')\n",
    "\n",
    "#Heroku\n",
    "dbname=os.getenv('HDATABASE')\n",
    "user=os.getenv('HUSER')\n",
    "password=os.getenv('HPASSWORD')\n",
    "host=os.getenv('HHOST')\n",
    "port=os.getenv('HPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando ao banco de dados PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=dbname,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Função para mapear os tipos de dados do Pandas para PostgreSQL\n",
    "def mapear_tipos_pandas_para_postgresql(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_object_dtype(dtype):\n",
    "        return \"TEXT\"\n",
    "    else:\n",
    "        return \"TEXT\"  # Tipo padrão\n",
    "\n",
    "# Função para criar a tabela no PostgreSQL com base nos dtypes do DataFrame\n",
    "def criar_tabela_com_dtypes(nome_tabela, df, schema='public'):\n",
    "    nome_completo_tabela = f\"{schema}.{nome_tabela}\"\n",
    "    colunas_com_tipos = \", \".join([f\"{col} {mapear_tipos_pandas_para_postgresql(dtype)}\" for col, dtype in df.dtypes.items()])\n",
    "    \n",
    "    # Criar a query SQL para criar a tabela\n",
    "    query = f\"CREATE TABLE IF NOT EXISTS {nome_completo_tabela} ({colunas_com_tipos});\"\n",
    "    \n",
    "    # Executar a query\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "\n",
    "# Inserindo os dados do DataFrame no banco de dados\n",
    "def inserir_dados(nome_tabela, df):\n",
    "    for index, row in df.iterrows():\n",
    "        columns = ', '.join(row.index)\n",
    "        values = ', '.join(['%s'] * len(row))\n",
    "        insert_query = sql.SQL(f\"INSERT INTO {nome_tabela} ({columns}) VALUES ({values})\")\n",
    "        cur.execute(insert_query, tuple(row))\n",
    "    conn.commit()\n",
    "\n",
    "# Nome da tabela\n",
    "nome_tabela = filename\n",
    "\n",
    "# Criando a tabela\n",
    "criar_tabela_com_dtypes(nome_tabela, all_data)\n",
    "\n",
    "# Inserindo os dados\n",
    "inserir_dados(nome_tabela, all_data)\n",
    "\n",
    "# Fechando a conexão\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
